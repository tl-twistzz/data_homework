{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    " - 数据质量：缺失值处理、异常处理、重复数据\n",
    " - 数据结构：格式转化、数据合并\n",
    "\n",
    "### 1. 删除重复数据，并输出去重前后的数据量\n",
    "### 2. 缺失值处理\n",
    "- 首先，去掉 gravatar_id 列，并查看各列的缺失值的情况\n",
    "- 其次，将可转化成 boolean 变量的列字段转化成 boolean 变量（转成布尔类型是为了便于处理缺失字段，如是否存在公司、位置等等），文本数据用空字符串填充空值......\n",
    "- 最后，再次看各列有无缺失值\n",
    "### 3. 数据变换，将created_at、updated_at转为时间戳\n",
    "### 4. 数据可视化\n",
    "- 4.1 可视化bot和hunman类型的情况（展示图表自选，并在报告中说明选择原因、结果分析以及数据洞察）\n",
    "- 4.2 可视化bot类型账号的created_at情况（展示图表自选，并在报告中说明选择原因、结果分析以及数据洞察）\n",
    "- 4.3 可视化human类型账号的created_at情况（展示图表自选，并在报告中说明选择原因、结果分析以及数据洞察）\n",
    "- 4.4 可视化bot类型账号的followers和following情况（展示图表自选，并在报告中说明选择原因、结果分析以及数据洞察）\n",
    "- 4.5 可视化human类型账号的followers和following情况（展示图表自选，并在报告中说明选择原因、结果分析以及数据洞察）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前的数据量: 20358\n",
      "去重后的数据量: 19779\n",
      "各列的缺失值情况:\n",
      " actor_id                   0\n",
      "label                      0\n",
      "login                      0\n",
      "id                         0\n",
      "node_id                    0\n",
      "avatar_url                 0\n",
      "url                        0\n",
      "html_url                   0\n",
      "followers_url              0\n",
      "following_url              0\n",
      "gists_url                  0\n",
      "starred_url                0\n",
      "subscriptions_url          0\n",
      "organizations_url          0\n",
      "repos_url                  0\n",
      "events_url                 0\n",
      "received_events_url        0\n",
      "type                       0\n",
      "site_admin                 0\n",
      "name                    2589\n",
      "company                 8982\n",
      "blog                   11263\n",
      "location                7080\n",
      "email                  11739\n",
      "hireable               16481\n",
      "bio                    10930\n",
      "twitter_username       14859\n",
      "public_repos               0\n",
      "public_gists               0\n",
      "followers                  0\n",
      "following                  0\n",
      "created_at                 0\n",
      "updated_at                 0\n",
      "dtype: int64\n",
      "处理缺失值后的各列缺失值情况:\n",
      " actor_id                  0\n",
      "label                     0\n",
      "login                     0\n",
      "id                        0\n",
      "node_id                   0\n",
      "avatar_url                0\n",
      "url                       0\n",
      "html_url                  0\n",
      "followers_url             0\n",
      "following_url             0\n",
      "gists_url                 0\n",
      "starred_url               0\n",
      "subscriptions_url         0\n",
      "organizations_url         0\n",
      "repos_url                 0\n",
      "events_url                0\n",
      "received_events_url       0\n",
      "type                      0\n",
      "site_admin                0\n",
      "name                   2589\n",
      "company                   0\n",
      "blog                      0\n",
      "location                  0\n",
      "email                     0\n",
      "hireable                  0\n",
      "bio                       0\n",
      "twitter_username          0\n",
      "public_repos              0\n",
      "public_gists              0\n",
      "followers                 0\n",
      "following                 0\n",
      "created_at                0\n",
      "updated_at                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "raw_data = pd.read_csv('data/github_bot_raw_data.csv')\n",
    "\n",
    "# 列字段解读\n",
    "columns = [\n",
    "    'actor_id', 'label', 'login', 'id', 'node_id', 'avatar_url', 'gravatar_id', 'url', 'html_url', 'followers_url',\n",
    "    'following_url', 'gists_url', 'starred_url', 'subscriptions_url', 'organizations_url', 'repos_url', 'events_url',\n",
    "    'received_events_url', 'type', 'site_admin', 'name', 'company', 'blog', 'location', 'email', 'hireable', 'bio',\n",
    "    'twitter_username', 'public_repos', 'public_gists', 'followers', 'following', 'created_at', 'updated_at'\n",
    "]\n",
    "\n",
    "# 选择需要的列\n",
    "data = raw_data[columns]\n",
    "\n",
    "# 查看去重前的数据量\n",
    "print(f\"去重前的数据量: {len(data)}\")\n",
    "\n",
    "# 删除重复数据\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# 查看去重后的数据量\n",
    "print(f\"去重后的数据量: {len(data)}\")\n",
    "\n",
    "# 缺失值处理\n",
    "data = data.drop(columns=['gravatar_id'])\n",
    "\n",
    "# 查看各列的缺失值情况\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"各列的缺失值情况:\\n\", missing_values)\n",
    "\n",
    "# 将可转化成 boolean 变量的列字段转化成 boolean 变量\n",
    "boolean_columns = ['site_admin', 'hireable']\n",
    "for col in boolean_columns:\n",
    "    data[col] = data[col].fillna(False).astype(bool)\n",
    "\n",
    "# 文本数据用空字符串填充空值\n",
    "text_columns = ['company', 'blog', 'location', 'email', 'bio', 'twitter_username']\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].fillna('')\n",
    "\n",
    "# 再次查看各列有无缺失值\n",
    "missing_values_after = data.isnull().sum()\n",
    "print(\"处理缺失值后的各列缺失值情况:\\n\", missing_values_after)\n",
    "\n",
    "# 改时间戳\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data['updated_at'] = pd.to_datetime(data['updated_at'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
